{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project- Dog-Vision.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FZCWa92bkib"
      },
      "outputs": [],
      "source": [
        "#!unzip \"drive/MyDrive/Dog-Vision/dog-breed-identificatioan.zip\" -d \"drive/MyDrive/Dog-Vision/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## END-TO-END-DOG-BREED-CLASSIFICATION-PROJECT"
      ],
      "metadata": {
        "id": "ZEutzEymvcPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dogs are incredible. But have you ever been sitting at a cafe, seen a dog and not known what breed it is? I have. And then someone says, \"it's an English Terrier\" and you think, how did they know that?\n",
        "\n",
        "In this project we're going to be using machine learning to help us identify different breeds of dogs.\n",
        "\n",
        "To do this, we'll be using data from the Kaggle dog breed identification competition. It consists of a collection of 10,000+ labelled images of 120 different dog breeds.\n",
        "\n",
        "This kind of problem is called multi-class image classification. It's multi-class because we're trying to classify mutliple different breeds of dog. If we were only trying to classify dogs versus cats, it would be called binary classification (one thing versus another).\n",
        "\n",
        "Multi-class image classification is an important problem because it's the same kind of technology Tesla uses in their self-driving cars or Airbnb uses in atuomatically adding information to their listings.\n",
        "\n",
        "Since the most important step in a deep learng problem is getting the data ready (turning it into numbers), that's what we're going to start with."
      ],
      "metadata": {
        "id": "UwlFcP2CzHcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to go through the following TensorFlow/Deep Learning workflow:\n",
        "\n",
        "1. Get data ready (download from Kaggle, store, import).\n",
        "2. Prepare the data (preprocessing, the 3 sets, X & y).\n",
        "3. Choose and fit/train a model (TensorFlow Hub, tf.keras.applications, TensorBoard, EarlyStopping).\n",
        "4. Evaluating a model (making predictions, comparing them with the ground truth labels).\n",
        "5. Improve the model through experimentation (start with 1000 images, make sure it works, increase the number of images).\n",
        "6. Save, sharing and reloading your model (once you're happy with the results)."
      ],
      "metadata": {
        "id": "S9qOGtYjzPpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For preprocessing our data, we're going to use TensorFlow 2.x. The whole premise here is to get our data into Tensors (arrays of numbers which can be run on GPUs) and then allow a machine learning model to find patterns between them.\n",
        "\n",
        "For our machine learning model, we're going to be using a pretrained deep learning model from TensorFlow Hub.\n",
        "\n",
        "The process of using a pretrained model and adapting it to your own problem is called transfer learning. We do this because rather than train our own model from scratch (could be timely and expensive), we leverage the patterns of another model which has been trained to classify images."
      ],
      "metadata": {
        "id": "oqr-dg4azfar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our workspace ready\n",
        "Before we get started, since we'll be using TensorFlow 2.x and TensorFlow Hub (TensorFlow Hub), let's import them.\n",
        "\n",
        "NOTE: Don't run the cell below if you're already using TF 2.x."
      ],
      "metadata": {
        "id": "bWnSNsh-zlDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import Tensorflow into Google collab\n",
        "import tensorflow as tf\n",
        "print (\"Tensorflow version : \",tf.__version__)"
      ],
      "metadata": {
        "id": "jcHGiQzmzuAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "print (\"Tensorflow Hub version : \",hub.__version__)"
      ],
      "metadata": {
        "id": "W9uHGFB10zg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "metadata": {
        "id": "SI9wa-bT1oVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Labels"
      ],
      "metadata": {
        "id": "yCNy19HG2CLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "labels_csv=pd.read_csv(\"drive/MyDrive/Dog-Vision/labels.csv\")"
      ],
      "metadata": {
        "id": "UJl_gsj4MbsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv.describe()"
      ],
      "metadata": {
        "id": "qz5vH79BM2Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv.head()"
      ],
      "metadata": {
        "id": "2XaANSrsNKKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"].value_counts()"
      ],
      "metadata": {
        "id": "0tC505AdNM_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))"
      ],
      "metadata": {
        "id": "obAKbA6rNjqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "rczShkwBNtIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"drive/MyDrive/Dog-Vision/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg\")"
      ],
      "metadata": {
        "id": "SNAVFIhYOkGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv.head()"
      ],
      "metadata": {
        "id": "Fv-2QkfHPHBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename=[\"drive/MyDrive/Dog-Vision/train/\"+fname+\".jpg\" for fname in labels_csv[\"id\"]]"
      ],
      "metadata": {
        "id": "cfGBNrQ6eDYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename"
      ],
      "metadata": {
        "id": "vNkhaTcBPDeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if len(os.listdir(\"drive/MyDrive/Dog-Vision/train/\")) ==len(filename):\n",
        "  print(\"Filenames are equal . Proceed\")\n",
        "else:\n",
        "  print(\"Filenames didnt match\")\n"
      ],
      "metadata": {
        "id": "1kPA1t2pet8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename[9000])"
      ],
      "metadata": {
        "id": "KSwqzUSxf9Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"][9000]"
      ],
      "metadata": {
        "id": "CSCdfsRXgiRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got list of our paths now convets images to numbers."
      ],
      "metadata": {
        "id": "-kJYrpZib4Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "labels = labels_csv[\"breed\"].to_numpy() \n",
        "# labels = np.array(labels) # does same thing as above\n",
        "labels"
      ],
      "metadata": {
        "id": "VJeKeKRjg6rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "wSiXb8Ujhbm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(labels)==len(filename):\n",
        "  print(\"Numebrs are equal proceed\")\n",
        "else:\n",
        "  print(\"Numbers arent equal\")"
      ],
      "metadata": {
        "id": "-MLK3625hgwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unique_breeds_list = np.unique(labels)\n",
        "len(unique_breeds_list)"
      ],
      "metadata": {
        "id": "_VfrUYxahu5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Turn single label into array of booleans\n",
        "\n",
        "This will convert create a list of boolens total elements will be the number of unique breeds and it will e only trur at 1 place ( where the actual breed is present in the list (position of breed). BostonBull is true at 19 and in unique breeds its present at 19|)"
      ],
      "metadata": {
        "id": "CF_zkBGuc5WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[0])\n",
        "## true where the label 0 exsist in unique_breeds_list\n",
        "labels[0]==unique_breeds_list"
      ],
      "metadata": {
        "id": "xcbDidY6dqIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Convert our every label of image into an np.array where one index is true and rest of them are false. Position of that one true will tell us about the brred each dog it fit in `"
      ],
      "metadata": {
        "id": "Y6xqlXtbzzv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## convert all labels to boolean\n",
        "boolen_labels=[label == unique_breeds_list for label in labels]"
      ],
      "metadata": {
        "id": "aP2wJ1xviqJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(boolen_labels)"
      ],
      "metadata": {
        "id": "GjbhnM9IjkGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning boolean into integer"
      ],
      "metadata": {
        "id": "7NSjmO6Kud7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[0])## original label\n",
        "print(np.where(unique_breeds_list== labels[0]))##index where label occurs\n",
        "print(boolen_labels[0].argmax())## index where label occurs in boolean array \n",
        "print(boolen_labels[0].astype(int))## there must be a 1 where sample label occurs"
      ],
      "metadata": {
        "id": "O2BaiRKHu0XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename[:10]"
      ],
      "metadata": {
        "id": "NR3loJL1vsow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boolen_labels[:2]"
      ],
      "metadata": {
        "id": "Qy_17DY6wcq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create our own validation set \n",
        "> since Kaggle doesnt provide the validation set we will crate our own"
      ],
      "metadata": {
        "id": "ZJ062DUEwluN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create x and y\n",
        "x=filename\n",
        "y=boolen_labels"
      ],
      "metadata": {
        "id": "6ZNFq-lRw8jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> we are going to start with 1000 images and radually images"
      ],
      "metadata": {
        "id": "7zCiwojdxW71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_IMAGES=1000 #@param {type:\"slider\",min:1000,max:10000,step:100}"
      ],
      "metadata": {
        "id": "5ovqajKmxkEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(\n",
        "    x[:NUM_IMAGES],\n",
        "    y[:NUM_IMAGES],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n"
      ],
      "metadata": {
        "id": "moDekJa2yllU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train),len(x_val),len(y_train),len(y_val)"
      ],
      "metadata": {
        "id": "JHXNcCAdzAwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:2],y_val[:2]"
      ],
      "metadata": {
        "id": "Sw97FXKWzGsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convet into tensers"
      ],
      "metadata": {
        "id": "mhe1JFDfzpzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### X values are file paths and Y values are boolean representation of those filepaths"
      ],
      "metadata": {
        "id": "AiTgf35C0OlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perprocessing (Turning images into tensores)\n",
        "1. Take image filepath as input\n",
        "2. Use tensorflow to read filepath and save it to \"image\"\n",
        "3. Turn our image jpg into tensors\n",
        "4. Resize image to (244,244)\n",
        "5. Reload Modified image"
      ],
      "metadata": {
        "id": "Cbafbyuv0aDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### See how an image looks "
      ],
      "metadata": {
        "id": "7rhZKK1F211I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imread\n",
        "image=imread(filename[42])\n",
        "image.shape"
      ],
      "metadata": {
        "id": "XCbUZeyr3DnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.max(),image.min()"
      ],
      "metadata": {
        "id": "2RxQxulo3XRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "kCMjSx2P3PUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert image to tensor\n",
        "tf.constant(image)"
      ],
      "metadata": {
        "id": "QZWlWT903exI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename[25])"
      ],
      "metadata": {
        "id": "bdFpcxfn3uqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=imread(filename[25])\n",
        "image"
      ],
      "metadata": {
        "id": "LmauJTES4EfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(image)"
      ],
      "metadata": {
        "id": "kHA9uqXN4JDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a function to preprocess image \n",
        "1. Take image filepath as input\n",
        "2. Use tensorflow to read filepath and save it to \"image\"\n",
        "3. Turn our image jpg into tensors\n",
        " 3.1 . Normalize cololur channels from [0-255] to [0 to 1]\n",
        "4. Resize image to (244,244)\n",
        "5. Reload Modified image"
      ],
      "metadata": {
        "id": "n_44JL9g4Oif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE=224\n",
        "\n",
        "def process_images(image_path):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns it into a Tensor.\n",
        "  \"\"\"\n",
        "  # Read in image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # Convert the colour channel values from 0-225 values to 0-1 values\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  # Resize the image to our desired size (224, 244)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "  return image"
      ],
      "metadata": {
        "id": "2oYmGmre5Lqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning data into batches"
      ],
      "metadata": {
        "id": "Cq2ukXpz-CD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Why we need to convert data into batch size\n",
        "Our computer wont be able to fit whole data into one go\n",
        "thats why we arrange them in patches of 32 so it wil be easy for computer to process"
      ],
      "metadata": {
        "id": "CvFDMLOyCtd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> before we convert images to patches we need tuples look like these(`image`,`label`)"
      ],
      "metadata": {
        "id": "raDRg6OhH0tD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a simple function to return a tuple of tensors\n",
        "\n",
        "\n",
        "  # Create a simple function to return a tuple (image, label)\n",
        "def get_images_label(image_path, label):\n",
        "  \"\"\"\n",
        "  Takes an image file path name and the associated label,\n",
        "  processes the image and returns a tuple of (image, label).\n",
        "  \"\"\"\n",
        "  image = process_images(image_path)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "iM-uBKxDIyyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(process_images(x[42]),tf.constant(y[42]))"
      ],
      "metadata": {
        "id": "b3gZXUAQR6bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we got a way to turn our data into tensors and labels now we have to make a function to convert x and y into batches"
      ],
      "metadata": {
        "id": "v1sCsC7g1Bj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=32"
      ],
      "metadata": {
        "id": "SVc4D93KSGJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "\n",
        "# Define the batch size, 32 is a good default\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a function to turn data into batches\n",
        "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (x) and label (y) pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n",
        "  Also accepts test data as input (no labels).\n",
        "  \"\"\"\n",
        "  # If the data is a test dataset, we probably don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
        "    data_batch = data.map(process_images).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "  \n",
        "  # If the data if a valid dataset, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                               tf.constant(y))) # labels\n",
        "    data_batch = data.map(get_images_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    # If the data is a training dataset, we shuffle it\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn filepaths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                              tf.constant(y))) # labels\n",
        "    \n",
        "    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(x))\n",
        "\n",
        "    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
        "    data = data.map(get_images_label)\n",
        "\n",
        "    # Turn the data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "  return data_batch"
      ],
      "metadata": {
        "id": "CC_YkREk1Z7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=create_data_batches(x_train,y_train)\n",
        "valid_data=create_data_batches(x_val,y_val,valid_data=True)"
      ],
      "metadata": {
        "id": "hBiwAGoW-Ej5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.element_spec,valid_data.element_spec"
      ],
      "metadata": {
        "id": "CGdm4oNR-ayV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Data \n",
        "> Thses area a bit hard to comprehend/Understand  so we will like to see them in action"
      ],
      "metadata": {
        "id": "RBX8THJr-k45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "# Create a function for viewing images in a data batch\n",
        "def show_25_images(images, labels):\n",
        "  \"\"\"\n",
        "  Displays 25 images from a data batch.\n",
        "  \"\"\"\n",
        "  # Setup the figure\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  # Loop through 25 (for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    # Create subplots (5 rows, 5 columns)\n",
        "    ax = plt.subplot(5, 5, i+1)\n",
        "    # Display an image\n",
        "    plt.imshow(images[i])\n",
        "    # Add the image label as the title\n",
        "    plt.title(unique_breeds_list[labels[i].argmax()])\n",
        "    # Turn gird lines off\n",
        "    plt.axis(\"off\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zxthgxtVAS1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images, train_labels)"
      ],
      "metadata": {
        "id": "PmdCEhkOD6dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images,val_labels=next(valid_data.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "wLvBS5f_EWry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_25_images(val_images,val_labels)"
      ],
      "metadata": {
        "id": "3ZML-fdhF9zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before we build a model \n",
        "`few things we need to define`\n",
        "1. Input shape (Our image shape in from of tensors)to our model \n",
        "2. Output shape(Image labels in from of tensors) to our model\n",
        "3. Url we want to use from tensorflow HUB\n",
        "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5"
      ],
      "metadata": {
        "id": "rY7PfRWMGEIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE=[None,IMG_SIZE,IMG_SIZE,3]\n",
        "OUTPUT_SHAPE=len(unique_breeds_list)\n",
        "MODEL_URL=\"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\""
      ],
      "metadata": {
        "id": "gaNrGF14G66Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ow we've got the inputs, outputs and model we're using ready to go. We can start to put them together\n",
        "\n",
        "There are many ways of building a model in TensorFlow but one of the best ways to get started is to use the Keras API.\n",
        "\n",
        "Defining a deep learning model in Keras can be as straightforward as saying, \"here are the layers of the model, the input shape and the output shape, let's go!\"\n",
        "\n",
        "Knowing this, let's create a function which:\n",
        "\n",
        "* Takes the input shape, output shape and the model we've chosen's URL as parameters.\n",
        "* Defines the layers in a Keras model in a sequential fashion (do this first, then this, then that).\n",
        "* Compiles the model (says how it should be evaluated and improved).\n",
        "* Builds the model (tells it what kind of input shape it'll be getting).\n",
        "* Returns the model.\n",
        "* We'll take a look at the code first, then dicuss each part."
      ],
      "metadata": {
        "id": "hI33kdMjifBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create model\n",
        "def create_model(input_shape=INPUT_SHAPE,output_shape=OUTPUT_SHAPE,model_url=MODEL_URL):\n",
        "  # Setup model layers\n",
        "  model=tf.keras.Sequential([\n",
        "      hub.KerasLayer(MODEL_URL) , # Layer1 input Layer\n",
        "      tf.keras.layers.Dense( units=OUTPUT_SHAPE,\n",
        "       activation =\"softmax\")\n",
        "  ])\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      metrics=[\"Accuracy\"]\n",
        "  )\n",
        "  # Build The model\n",
        "  model.build(INPUT_SHAPE)\n",
        "  return model"
      ],
      "metadata": {
        "id": "IzZq1tVJnDRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()"
      ],
      "metadata": {
        "id": "LnPQlyRVqUYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qe7xh3KRq7LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create some call backs \n",
        "> call backs are helpfull functions that a model can use during training and do things such as save its progress and also stop execution if model isnt improving.\n"
      ],
      "metadata": {
        "id": "AKiBP6xloMiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create two models \n",
        "* One of tensor board to keep track of our progress.\n",
        "* Second to stop model to prevent overfitting"
      ],
      "metadata": {
        "id": "EzUqudxGrRVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorboard call back"
      ],
      "metadata": {
        "id": "Z16yUVn2pWmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tensorboard\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "mwl_flonpfkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To setup tensorboard callback we need to do 3 things:\n",
        "1. Load tensorboard notebook extention.\n",
        "2. Create tensorboard callbacks which is able to save logs into a directory and pass it to out `fit()` function\n",
        "3. Visualize our logs training with %tensorboard magic function(do this after model training)"
      ],
      "metadata": {
        "id": "brMoPOCKp_dQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log directory for storing TensorBoard logs\n",
        "  logdir = os.path.join(\"/drive/MyDrive/Dog-Vision/logs\",\n",
        "                        # Make it so the logs get tracked whenever we run an experiment\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "KOoyBHO_q-9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early stopping callabck\n",
        "check this resourse https://keras.io/api/callbacks/early_stopping/"
      ],
      "metadata": {
        "id": "5p8wuWVysfDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_Accuracy\",\n",
        "                                                  patience=3) # stops after 3 rounds of no improvements"
      ],
      "metadata": {
        "id": "Mr075dH2s5Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model"
      ],
      "metadata": {
        "id": "DKPtPbUrty5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPHOCS=100 #@param{type:\"slider\",min:10,max:100,step:10}"
      ],
      "metadata": {
        "id": "PqZwShPau5fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create functions that train model\n",
        "\n",
        "* create a model using `create_model()`\n",
        "* create a tensorboard call back using `create tensorboard call back`\n",
        "* call fit fuction on model passing train,val data passing no. of ephocs \n",
        "* Return model"
      ],
      "metadata": {
        "id": "l0Nb2H7QvUZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "  \"\"\"\n",
        "  Train a given model and return a trained version\n",
        "  \"\"\"\n",
        "  ## create model\n",
        "  model=create_model()\n",
        "  ## Create new tensorboard session every time we train a new model\n",
        "  tensorboard=create_tensorboard_callback()\n",
        "  # Fit model to data passing it callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPHOCS,\n",
        "            validation_data=valid_data,\n",
        "            validation_freq=1,\n",
        "            callbacks=[tensorboard,early_stopping])\n",
        "  return model"
      ],
      "metadata": {
        "id": "iF8C_DuAwSa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=train_model()"
      ],
      "metadata": {
        "id": "NI81A-5Bx7Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> OverFitting a model is a good thing .It means that our model is learning!!!!"
      ],
      "metadata": {
        "id": "pLKbA-0oyCmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our model has been trained, we can make its performance visual by checking the TensorBoard logs.\n",
        "\n",
        "The TensorBoard magic function (%tensorboard) will access the logs directory we created earlier and viualize its contents."
      ],
      "metadata": {
        "id": "OVEpiwEQoubZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir drive/MyDrive/Dog-Vision/logs"
      ],
      "metadata": {
        "id": "3wqK_atNncKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "NomKOBm-nf9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(valid_data,verbose=1)"
      ],
      "metadata": {
        "id": "kyhxPopM6EOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "id": "AAK4LuPjI9gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "metadata": {
        "id": "Ef7zxUBkJJhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions[0])"
      ],
      "metadata": {
        "id": "NxypxRghJVGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First prediction\n",
        "index=42\n",
        "print(predictions[0])\n",
        "print(f\"Max value (probability of prediction): {np.max(predictions[index])}\") # the max probability value predicted by the model\n",
        "print(f\"Sum: {np.sum(predictions[index])}\") # because we used softmax activation in our model, this will be close to 1\n",
        "print(f\"Max index: {np.argmax(predictions[index])}\") # the index of where the max value in predictions[0] occurs\n",
        "print(f\"Predicted label: {unique_breeds_list[np.argmax(predictions[index])]}\") # the predicted label"
      ],
      "metadata": {
        "id": "IXjzNtJ_JeFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing images on which perdiction is being made \n",
        "> Note : Prediction Probability is also called confidance interval"
      ],
      "metadata": {
        "id": "1R-yDyIUNVtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_label(prediction_probabilities):\n",
        "  \"\"\"\n",
        "  Turns an array of prediction probabilities into a label.\n",
        "  \"\"\"\n",
        "  return unique_breeds_list[np.argmax(prediction_probabilities)]\n",
        "\n",
        "# Get a predicted label based on an array of prediction probabilities\n",
        "pred_label = get_pred_label(predictions[0])\n",
        "pred_label"
      ],
      "metadata": {
        "id": "xUWuMCkmdEc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our validation data is still in batch format we need to unbatch it for thet we need to create a function to unbatch all batchs"
      ],
      "metadata": {
        "id": "KJQT6Sr_eMel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to unbatch a batched dataset\n",
        "def unbatchify(data):\n",
        "  \"\"\"\n",
        "  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n",
        "  of images and labels.\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  labels = []\n",
        "  # Loop through unbatched data\n",
        "  for image, label in data.unbatch().as_numpy_iterator():\n",
        "    images.append(image)\n",
        "    labels.append(unique_breeds_list[np.argmax(label)])\n",
        "  return images, labels\n",
        "\n",
        "# Unbatchify the validation data\n",
        "val_images, val_labels = unbatchify(valid_data)\n",
        "val_images[0], val_labels[0]"
      ],
      "metadata": {
        "id": "yVorJqYMe5bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred_label(val_labels[0])"
      ],
      "metadata": {
        "id": "6TIzHNA5fhfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred_label(predictions[0])"
      ],
      "metadata": {
        "id": "GU5QDR0If9Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we got the ways of getting:\n",
        "* Predicting labels\n",
        "* Predicting Images\n",
        "* Validation Images\n",
        "\n",
        "Lets create a function to visualize them\n",
        "* That function will take prediction probabilities,array of truth labels and array of images and integers\n",
        "* convert prediction probability into prediction label\n",
        "* Plot predicted label ,its predicted probability,the truth label and target on single plot"
      ],
      "metadata": {
        "id": "TPNqKcSUgh0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(prediction_probabilities, labels, images, n=1):\n",
        "  \"\"\"\n",
        "  View the prediction, ground truth label and image for sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n",
        "  \n",
        "  # Get the pred label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "  \n",
        "  # Plot image & remove ticks\n",
        "  plt.imshow(image)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  # Change the color of the title depending on if the prediction is right or wrong?\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n",
        "                                      np.max(pred_prob)*100,\n",
        "                                      true_label),\n",
        "                                      color=color)"
      ],
      "metadata": {
        "id": "gwW3h4cgUH4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(prediction_probabilities=predictions,\n",
        "          labels=val_labels,\n",
        "          images=val_images,\n",
        "          n=77)"
      ],
      "metadata": {
        "id": "czpzMej-W6BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, suffix=None):\n",
        "  \"\"\"\n",
        "  Saves a given model in a models directory and appends a suffix (string).\n",
        "  \"\"\"\n",
        "  # Create a model directory pathname with current time\n",
        "  modeldir = os.path.join(\"drive/MyDrive/Dog-Vision/models\",\n",
        "                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
        "  print(f\"Saving model to: {model_path}...\")\n",
        "  model.save(model_path)\n",
        "  return model_path"
      ],
      "metadata": {
        "id": "uM9zcw1QqGJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to load a trained model\n",
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Loads a saved model from a specified path.\n",
        "  \"\"\"\n",
        "  print(f\"Loading saved model from: {model_path}\")\n",
        "  model = tf.keras.models.load_model(model_path, \n",
        "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  return model"
      ],
      "metadata": {
        "id": "Zn4VSGZlxKat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(model,suffix=\"1000-image-adam-mobilenetv2-model\")"
      ],
      "metadata": {
        "id": "wYac-CfRx9dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_1000_image_model=load_model(\"/content/drive/MyDrive/Dog-Vision/models/20220819-20261660940784-1000-image-adam-mobilenetv2-model.h5\")"
      ],
      "metadata": {
        "id": "UrHDrG7vyiuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(valid_data)"
      ],
      "metadata": {
        "id": "BjnNFKLZyRJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_1000_image_model.evaluate(valid_data)"
      ],
      "metadata": {
        "id": "7Rp9WSMqy_kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a big dog model (on the full data)"
      ],
      "metadata": {
        "id": "b-1UCQ7SzG38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(x),len(y)"
      ],
      "metadata": {
        "id": "gYfrc3h2zXkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data=create_data_batches(x,y)"
      ],
      "metadata": {
        "id": "bWtVEI3tzdV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data"
      ],
      "metadata": {
        "id": "ewHINGfHVsAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model=create_model()"
      ],
      "metadata": {
        "id": "PWMgri6fVw85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model_tensorbaord=create_tensorboard_callback()\n"
      ],
      "metadata": {
        "id": "AAPuupHqXpD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"Accuracy\",\n",
        "                                                  patience=3)"
      ],
      "metadata": {
        "id": "KCRxFdFAYVdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=full_data,\n",
        "          epochs=NUM_EPHOCS,\n",
        "          callbacks=[full_model_tensorbaord,full_model_early_stopping])"
      ],
      "metadata": {
        "id": "eYo3zcP4Yxyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(full_model,suffix=\"full_imageset_mobilnetv2_adam\")"
      ],
      "metadata": {
        "id": "BQnut6_5aMwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_full=load_model(\"drive/MyDrive/Dog-Vision/models/20220820-18031661018618-full_imageset_mobilnetv2_adam.h5\")"
      ],
      "metadata": {
        "id": "vARac8OqbLk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing TestData"
      ],
      "metadata": {
        "id": "zJfyv1SFbtyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions on the test dataset\n",
        "Since our model has been trained on images in the form of Tensor batches, to make predictions on the test data, we'll have to get it into the same format.\n",
        "\n",
        "Luckily we created create_data_batches() earlier which can take a list of filenames as input and conver them into Tensor batches.\n",
        "\n",
        "To make predictions on the test data, we'll:\n",
        "\n",
        "Get the test image filenames. ✅\n",
        "Convert the filenames into test data batches using create_data_batches() and setting the test_data parameter to True (since the test data doesn't have labels). ✅\n",
        "Make a predictions array by passing the test batches to the predict() method called on our model."
      ],
      "metadata": {
        "id": "NUC-MmL8eCYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_filenames=[\"drive/MyDrive/Dog-Vision/test/\" + fname for fname in os.listdir(\"drive/MyDrive/Dog-Vision/test\")]"
      ],
      "metadata": {
        "id": "tDlAzutMdL_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_filenames"
      ],
      "metadata": {
        "id": "YecjOiTPdV64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####create test data batches"
      ],
      "metadata": {
        "id": "sTHZAXi8dYMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_data= create_data_batches(test_filenames,test_data=True)"
      ],
      "metadata": {
        "id": "VvUfFoPUeQOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "hUJfJhG6esoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictios=loaded_model_full.predict(test_data,verbose=1)"
      ],
      "metadata": {
        "id": "WY7hboTmezvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt(\"drive/MyDrive/Dog-Vision/preds-array.csv\",test_predictios,delimiter=\",\")"
      ],
      "metadata": {
        "id": "_H9_bowYf6mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.loadtxt(\"drive/MyDrive/Dog-Vision/preds-array.csv\",delimiter=\",\")"
      ],
      "metadata": {
        "id": "yLqAgbhqiZJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictios.shape"
      ],
      "metadata": {
        "id": "LVz8lSo-isqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing test dataset predictions for Kaggle\n",
        "Looking at the Kaggle sample submission, we find that it wants our models prediction probaiblity outputs in a DataFrame with an ID and a column for each different dog breed. https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "\n",
        "To get the data in this format, we'll:\n",
        "\n",
        "Create a pandas DataFrame with an ID column as well as a column for each dog breed. ✅\n",
        "Add data to the ID column by extracting the test image ID's from their filepaths.\n",
        "Add data (the prediction probabilites) to each of the dog breed columns.\n",
        "Export the DataFrame as a CSV to submit it to Kaggle."
      ],
      "metadata": {
        "id": "UbgnwaXfjUiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df=pd.DataFrame(columns=[\"id\"]+list(unique_breeds_list))"
      ],
      "metadata": {
        "id": "-isg6GzCjwpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df.head()"
      ],
      "metadata": {
        "id": "_OXgxQA6kMG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path=\"drive/MyDrive/Dog-Vision/test/\""
      ],
      "metadata": {
        "id": "A269RJ9JkPMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids= [os.path.splitext(path)[0] for path in os.listdir(test_path)]"
      ],
      "metadata": {
        "id": "GBen6smSkrd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df[\"id\"]=test_ids"
      ],
      "metadata": {
        "id": "XHZ5xgA6k8RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df.tail()"
      ],
      "metadata": {
        "id": "QSF-I9r6lS6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df[list(unique_breeds_list)] = test_predictios"
      ],
      "metadata": {
        "id": "ck0KKbQulVN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df"
      ],
      "metadata": {
        "id": "UbY2cWnylro3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df.to_csv(\"drive/MyDrive/Dog-Vision/full_model_submission_for_model_2\",index=False)"
      ],
      "metadata": {
        "id": "EndoLmdcmzHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WpCJRekQnDax"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}